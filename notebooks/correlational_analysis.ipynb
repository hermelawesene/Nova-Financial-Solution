{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing stock data\n",
    "dataAAPL = pd.read_csv('../data/AAPL_historical_data.csv', index_col='Date', parse_dates=True)\n",
    "dataAMZN = pd.read_csv('../data/AMZN_historical_data.csv', index_col='Date', parse_dates=True)\n",
    "dataGOOG = pd.read_csv('../data/GOOG_historical_data.csv', index_col='Date', parse_dates=True)\n",
    "dataMETA = pd.read_csv('../data/META_historical_data.csv', index_col='Date', parse_dates=True)\n",
    "dataMSFT = pd.read_csv('../data/MSFT_historical_data.csv', index_col='Date', parse_dates=True)\n",
    "dataNVDA = pd.read_csv('../data/NVDA_historical_data.csv', index_col='Date', parse_dates=True)\n",
    "dataTSLA = pd.read_csv('../data/TSLA_historical_data.csv', index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the exosting news data\n",
    "news_data = pd.read_csv('../data/raw_analyst_ratings.csv', parse_dates=['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime and adjust to UTC\n",
    "news_data['date'] = pd.to_datetime(news_data['date'], utc=True, format='mixed')\n",
    "dataAAPL.index = pd.to_datetime(dataAAPL.index, utc=True)\n",
    "\n",
    "\n",
    "# Extract just the date part\n",
    "news_data['date'] = news_data['date'].dt.date\n",
    "# To extract the date index\n",
    "dates = dataAAPL.index\n",
    "dataAAPL = dataAAPL.reset_index()\n",
    "\n",
    "dataAAPL['Date'] = dataAAPL['Date'].dt.date\n",
    "\n",
    "# Calculate daily percentage changes\n",
    "dataAAPL['Daily_Return'] = dataAAPL['Close'].pct_change() * 100  # Multiply by 100 to get percentage\n",
    "\n",
    "\n",
    "# Merge on the date\n",
    "merged_data = pd.merge(news_data, dataAAPL, left_on='date', right_on='Date', how='left')\n",
    "\n",
    "# Handle non-trading days by filling missing stock data with the closest trading day\n",
    "merged_data = merged_data.ffill()  # Forward fill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Data:\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "         date stock        Date       Open       High        Low      Close  \\\n",
      "0  2020-06-05     A  2020-06-05  80.837502  82.937500  80.807503  82.875000   \n",
      "1  2020-06-03     A  2020-06-03  81.165001  81.550003  80.574997  81.279999   \n",
      "2  2020-05-26     A  2020-05-26  80.875000  81.059998  79.125000  79.182503   \n",
      "3  2020-05-22     A  2020-05-22  78.942497  79.807503  78.837502  79.722504   \n",
      "4  2020-05-22     A  2020-05-22  78.942497  79.807503  78.837502  79.722504   \n",
      "\n",
      "   Adj Close       Volume  Dividends  Stock Splits  Daily_Return  \n",
      "0  80.843407  137250400.0        0.0           0.0      2.848099  \n",
      "1  79.287506  104491200.0        0.0           0.0      0.550504  \n",
      "2  77.241432  125522000.0        0.0           0.0     -0.677351  \n",
      "3  77.768188   81803200.0        0.0           0.0      0.643840  \n",
      "4  77.768188   81803200.0        0.0           0.0      0.643840  \n",
      "Date range in merged data:\n",
      "2009-02-14 2020-06-11\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMerged Data:\")\n",
    "print(merged_data.head())\n",
    "print(\"Date range in merged data:\")\n",
    "print(merged_data['date'].min(), merged_data['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data with Sentiment Scores:\n",
      "         Unnamed: 0                                           headline  \\\n",
      "0                 0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1                 1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2                 2                      71 Biggest Movers From Friday   \n",
      "3                 3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4                 4  B of A Securities Maintains Neutral on Agilent...   \n",
      "...             ...                                                ...   \n",
      "1407323     1413844             Top Narrow Based Indexes For August 29   \n",
      "1407324     1413845  Recap: Wednesday's Top Percentage Gainers and ...   \n",
      "1407325     1413846  UPDATE: Oppenheimer Color on China Zenix Auto ...   \n",
      "1407326     1413847  Oppenheimer Initiates China Zenix At Outperfor...   \n",
      "1407327     1413848  China Zenix Auto International Opens For Tradi...   \n",
      "\n",
      "                                                       url          publisher  \\\n",
      "0        https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1        https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2        https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3        https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4        https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "...                                                    ...                ...   \n",
      "1407323  https://www.benzinga.com/news/11/08/1888782/to...      Monica Gerson   \n",
      "1407324  https://www.benzinga.com/news/earnings/11/06/1...       Benjamin Lee   \n",
      "1407325  https://www.benzinga.com/analyst-ratings/analy...     BenzingaStaffL   \n",
      "1407326  https://www.benzinga.com/analyst-ratings/price...          Joe Young   \n",
      "1407327  https://www.benzinga.com/news/ipos/11/05/10789...      Allie Wickman   \n",
      "\n",
      "               date stock        Date       Open       High        Low  \\\n",
      "0        2020-06-05     A  2020-06-05  80.837502  82.937500  80.807503   \n",
      "1        2020-06-03     A  2020-06-03  81.165001  81.550003  80.574997   \n",
      "2        2020-05-26     A  2020-05-26  80.875000  81.059998  79.125000   \n",
      "3        2020-05-22     A  2020-05-22  78.942497  79.807503  78.837502   \n",
      "4        2020-05-22     A  2020-05-22  78.942497  79.807503  78.837502   \n",
      "...             ...   ...         ...        ...        ...        ...   \n",
      "1407323  2011-08-29    ZX  2011-08-29  13.863571  13.982143  13.857143   \n",
      "1407324  2011-06-22    ZX  2011-06-22  11.612857  11.746429  11.513571   \n",
      "1407325  2011-06-21    ZX  2011-06-21  11.310000  11.635714  11.257143   \n",
      "1407326  2011-06-21    ZX  2011-06-21  11.310000  11.635714  11.257143   \n",
      "1407327  2011-05-12    ZX  2011-05-12  12.361429  12.397143  12.223929   \n",
      "\n",
      "             Close  Adj Close       Volume  Dividends  Stock Splits  \\\n",
      "0        82.875000  80.843407  137250400.0        0.0           0.0   \n",
      "1        81.279999  79.287506  104491200.0        0.0           0.0   \n",
      "2        79.182503  77.241432  125522000.0        0.0           0.0   \n",
      "3        79.722504  77.768188   81803200.0        0.0           0.0   \n",
      "4        79.722504  77.768188   81803200.0        0.0           0.0   \n",
      "...            ...        ...          ...        ...           ...   \n",
      "1407323  13.927500  11.761426  405269200.0        0.0           0.0   \n",
      "1407324  11.521786   9.729860  390583200.0        0.0           0.0   \n",
      "1407325  11.617857   9.810995  493382400.0        0.0           0.0   \n",
      "1407326  11.617857   9.810995  493382400.0        0.0           0.0   \n",
      "1407327  12.377500  10.452490  322000000.0        0.0           0.0   \n",
      "\n",
      "         Daily_Return  sentiment_score  \n",
      "0            2.848099           0.0000  \n",
      "1            0.550504           0.0000  \n",
      "2           -0.677351           0.0000  \n",
      "3            0.643840           0.0000  \n",
      "4            0.643840           0.2960  \n",
      "...               ...              ...  \n",
      "1407323      1.665877           0.2023  \n",
      "1407324     -0.826927          -0.3818  \n",
      "1407325      3.165035           0.0000  \n",
      "1407326      3.165035           0.0000  \n",
      "1407327     -0.190072           0.0000  \n",
      "\n",
      "[1407328 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Perform sentiment analysis on headlines\n",
    "def get_sentiment_score(text):\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    return sentiment['compound']  # Compound score\n",
    "\n",
    "# Apply sentiment analysis\n",
    "merged_data['sentiment_score'] = merged_data['headline'].apply(get_sentiment_score)\n",
    "\n",
    "# Display the merged DataFrame with sentiment scores\n",
    "print(\"Merged Data with Sentiment Scores:\")\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date  sentiment_score\n",
      "0     2009-02-14         0.226300\n",
      "1     2009-04-27         0.000000\n",
      "2     2009-04-29         0.000000\n",
      "3     2009-05-22         0.000000\n",
      "4     2009-05-27         0.751050\n",
      "...          ...              ...\n",
      "3950  2020-06-07         0.040156\n",
      "3951  2020-06-08         0.250061\n",
      "3952  2020-06-09         0.283393\n",
      "3953  2020-06-10         0.044021\n",
      "3954  2020-06-11         0.122841\n",
      "\n",
      "[3955 rows x 2 columns]\n",
      "2009-02-14 2020-06-11\n"
     ]
    }
   ],
   "source": [
    "# Aggregate sentiment scores by date (compute the average)\n",
    "daily_sentiments = merged_data.groupby('date')['sentiment_score'].mean().reset_index()\n",
    "\n",
    "# Display the daily sentiment scores\n",
    "print(daily_sentiments)\n",
    "print(daily_sentiments['date'].min(), daily_sentiments['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure stock data contains 'Date' and 'Daily_Return' columns\n",
    "dataAAPL = dataAAPL.rename(columns={'Date': 'date'})\n",
    "dataAAPL = dataAAPL[['date', 'Daily_Return']]  # Ensure only relevant columns are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge aggregated sentiment scores with stock data\n",
    "merged_data = pd.merge(daily_sentiments, dataAAPL, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation between sentiment scores and daily returns\n",
    "correlation = merged_data[['sentiment_score', 'Daily_Return']].corr().iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data with Aggregated Sentiments and Daily Returns:\n",
      "            date  sentiment_score  Daily_Return\n",
      "0     2009-02-14         0.226300           NaN\n",
      "1     2009-04-27         0.000000      0.669889\n",
      "2     2009-04-29         0.000000      1.000808\n",
      "3     2009-05-22         0.000000     -1.352874\n",
      "4     2009-05-27         0.751050      1.735759\n",
      "...          ...              ...           ...\n",
      "3950  2020-06-07         0.040156           NaN\n",
      "3951  2020-06-08         0.250061      0.591249\n",
      "3952  2020-06-09         0.283393      3.157800\n",
      "3953  2020-06-10         0.044021      2.572751\n",
      "3954  2020-06-11         0.122841     -4.801044\n",
      "\n",
      "[3955 rows x 3 columns]\n",
      "\n",
      "Correlation between Sentiment Scores and Daily Returns: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"Merged Data with Aggregated Sentiments and Daily Returns:\")\n",
    "print(merged_data)\n",
    "print(f\"\\nCorrelation between Sentiment Scores and Daily Returns: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Daily_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>-5.217061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>-7.339788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>2.475091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>2.899246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  Daily_Return\n",
       "0  1980-12-12           NaN\n",
       "1  1980-12-15     -5.217061\n",
       "2  1980-12-16     -7.339788\n",
       "3  1980-12-17      2.475091\n",
       "4  1980-12-18      2.899246"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index to make 'Date' a column and rename it to 'date'\n",
    "daily_returns = dataAAPL.reset_index()[['date', 'Daily_Return']]\n",
    "daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient between average daily sentiment scores and stock daily returns: 0.14605816008631772\n"
     ]
    }
   ],
   "source": [
    "#Merge sentiment scores with stock returns\n",
    "merged_data = pd.merge(daily_sentiments, daily_returns, on='date', how='inner')\n",
    "\n",
    "# Calculate the Pearson correlation coefficient\n",
    "correlation = merged_data[['sentiment_score', 'Daily_Return']].corr().iloc[0, 1]\n",
    "print(\"Pearson correlation coefficient between average daily sentiment scores and stock daily returns:\", correlation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
